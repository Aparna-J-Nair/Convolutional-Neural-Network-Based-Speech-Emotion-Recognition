{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Import audio packages\n",
    "import librosa\n",
    "import librosa.display\n",
    "from scipy.io import wavfile\n",
    "import scipy.io.wavfile\n",
    "import sys\n",
    "\n",
    "#Import plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#Import Keras & Tensorflow packages\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "\n",
    "#Emotions to observe\n",
    "observed_emotions=['neutral','calm', 'happy', 'sad', 'angry', 'fearful', 'disgust','surprised']\n",
    "\n",
    "\n",
    "def extract_feature(file_name, mfcc):\n",
    "        X,sample_rate = librosa.load(os.path.join(file_name), res_type='kaiser_fast')\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack(mfccs)\n",
    "        return result\n",
    "def dataset_options():\n",
    "    ravdess = True\n",
    "    data = {'ravdess':ravdess}\n",
    "    return data\n",
    "\n",
    "def load_data(test_size=0.2):\n",
    "    x,y = [],[]\n",
    "    mfcc=True\n",
    "    \n",
    "    data = dataset_options()\n",
    "    paths=[]\n",
    "    path = paths.append() #(load the path of dataset....\\Actor_*\\\\*.wav\")\n",
    "    \n",
    "    for path in paths:\n",
    "        for file in glob.glob(path):\n",
    "            file_name=os.path.basename(file)\n",
    "            emotion=emotions[file_name.split(\"-\")[2]]\n",
    "            if emotion not in observed_emotions:\n",
    "                continue\n",
    "            feature=extract_feature(file, mfcc)\n",
    "            x.append(feature)\n",
    "            y.append(emotion)\n",
    "    return {\"X\":x,\"y\":y}\n",
    "\n",
    "\n",
    "#PLOTTING AN AUDIO WAVE FROM DATASET\n",
    "\n",
    "#librosa.core.load(path, sr=22050, mono=True, offset=0.0, duration=None, dtype=<class 'numpy.float32'>, res_type='kaiser_best')\n",
    "res_type_s = 'kaiser_best'\n",
    "duration_s = None\n",
    "sample_rate_s = 22050\n",
    "offset_s = 0.5\n",
    "\n",
    "# y = audio time series\n",
    "# sample_rate = sampling rate of y\n",
    "\n",
    "y, sample_rate = librosa.load() #load the path of a wave from dataset..........\\Actor_03/03-01-01-01-02-02-03.wav, \n",
    "                                  res_type = res_type_s,\n",
    "                                  duration = duration_s,\n",
    "                                  sr = sample_rate_s,\n",
    "                                  offset = offset_s,\n",
    "                                 mono=False)\n",
    "                                 \n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(y, sr=sample_rate)\n",
    "\n",
    "\n",
    "#PLOTTING MFCC OF THE ABOVE AUDIO WAVE EXAMPLE\n",
    "\n",
    "librosa_audio, librosa_sample_rate = librosa.load() #load the path of a wave from dataset....\\Actor_03/03-01-01-01-02-02-03.wav\n",
    "\n",
    "mfccs = librosa.feature.mfcc(y=librosa_audio, sr=librosa_sample_rate, n_mfcc=40)\n",
    "print(mfccs.shape)\n",
    "\n",
    "import librosa.display\n",
    "librosa.display.specshow(mfccs, sr=librosa_sample_rate, x_axis='time')\n",
    "\n",
    "#FEATURES\n",
    "\n",
    "import time\n",
    "start_time=time.time()\n",
    "Trail_dict = load_data(test_size=0.2)\n",
    "X = pd.DataFrame(Trail_dict[\"X\"])\n",
    "y = pd.DataFrame(Trail_dict[\"y\"])\n",
    "data = pd.concat([X,y],join='outer',axis=1)\n",
    "data.columns=['feature1','feature2','feature3','feature4','feature5','feature6','feature7','feature8','feature9','feature10','feature11',\n",
    "             'feature12','feature13','feature14','feature15','feature16','feature17','feature18','feature19','feature20','feature21','feature22',\n",
    "              'feature23',\n",
    "             'feature24','feature25','feature26','feature27','feature28','feature29','feature30','feature31','feature32',\n",
    "              'feature33','feature34','feature35','feature36','feature37','feature38','feature39','feature40','emotion'\n",
    "             ]\n",
    "data['emotion']=data['emotion'].astype('object')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "data['emotion']=le.fit_transform(data['emotion'])\n",
    "data.head()\n",
    "\n",
    "\n",
    "#SPLITTING DATASET (TRAINING AND TESTING)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Split train & test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Check out the data\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')\n",
    "\n",
    "\n",
    "#LABLE ENCODING\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "#Encode emotion labels into numbers\n",
    "y_train_lb = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test_lb = np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "# Check out the data\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train shape: {y_train_lb.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_test shape: {y_test_lb.shape}')\n",
    "\n",
    "\n",
    "#Check encoding\n",
    "np.unique(y_train_lb, axis=0)\n",
    "\n",
    "\n",
    "#Check encoding labels\n",
    "print(lb.classes_)\n",
    "\n",
    "\n",
    "#Building new lists of encoding labels\n",
    "y_labels_encoded = {}\n",
    "for i, label in enumerate(lb.classes_):\n",
    "    y_labels_encoded[i] = label\n",
    "    \n",
    "print(y_labels_encoded)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#SCALING THE DATA\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scalled = scaler.transform(X_train)\n",
    "X_test_scalled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "#Adding dimension for CNN\n",
    "x_traincnn = np.expand_dims(X_train_scalled, axis=2)\n",
    "x_testcnn = np.expand_dims(X_test_scalled, axis=2)\n",
    "\n",
    "#Checking shapes of dataframes\n",
    "print(x_traincnn.shape)\n",
    "print(x_testcnn.shape)\n",
    "\n",
    "#Importing packages for CNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Conv1D \n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, BatchNormalization, Flatten, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#BUILDING CNN MODEL\n",
    "CNN_model = Sequential()\n",
    "\n",
    "#Build first layer\n",
    "CNN_model.add(Conv1D(16, 5,padding='same',\n",
    "                 input_shape=(40, 1), activation='relu'))\n",
    "CNN_model.add(Dropout(0.2))\n",
    "CNN_model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "#Build second layer\n",
    "CNN_model.add(Conv1D(32, 5,padding='same',activation='relu'))\n",
    "CNN_model.add(Dropout(0.2))\n",
    "CNN_model.add(MaxPooling1D(pool_size=(2)))\n",
    "#Build third layer\n",
    "CNN_model.add(Conv1D(64, 5,padding='same',activation='relu'))\n",
    "CNN_model.add(Dropout(0.3))\n",
    "CNN_model.add(MaxPooling1D(pool_size=(2)))\n",
    "#Build forth layer\n",
    "CNN_model.add(Conv1D(128, 5,padding='same',activation='relu'))\n",
    "CNN_model.add(Dropout(0.5))\n",
    "CNN_model.add(MaxPooling1D(pool_size=(2)))\n",
    "#Add dropout\n",
    "CNN_model.add(Dropout(0.3))\n",
    "\n",
    "#Flatten \n",
    "CNN_model.add(Flatten())\n",
    "\n",
    "CNN_model.add(Dense(128, activation ='relu'))\n",
    "CNN_model.add(Dropout(0.1))\n",
    "CNN_model.add(Dense(64, activation ='relu'))\n",
    "CNN_model.add(Dense(8, activation='softmax'))\n",
    "# CNN model summary\n",
    "CNN_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# COMPILING THE MODEL \n",
    "CNN_model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = 'Adam',\n",
    "                  metrics = ['accuracy'])\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_cnn.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "#MODEL FIT\n",
    "cnn_results = CNN_model.fit(x_traincnn, y_train_lb,\n",
    "              batch_size = 64,\n",
    "              epochs = 25,\n",
    "              verbose = 1,\n",
    "              validation_data = (x_testcnn, y_test_lb))\n",
    "\n",
    "\n",
    "\n",
    "#Ploting model accuracy over ephocs\n",
    "plt.plot(cnn_results.history['accuracy'])\n",
    "plt.plot(cnn_results.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Evaluating the model on the training and testing set\n",
    "score = CNN_model.evaluate(x_traincnn, y_train_lb, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = CNN_model.evaluate(x_testcnn, y_test_lb, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])\n",
    "\n",
    "\n",
    "#Get predictions from model\n",
    "y_test_predictions = CNN_model.predict_classes(x_testcnn)\n",
    "print(y_test_predictions)\n",
    "\n",
    "\n",
    "#Get labels for emotions\n",
    "print(y_labels_encoded)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#BUILDING CONFUSION MATRIX \n",
    "confusion_matrix = confusion_matrix(y_test, y_test_predictions_labels)\n",
    "print(confusion_matrix)\n",
    "\n",
    "\n",
    "#PLOTTING HEAT MAP\n",
    "ax = sns.heatmap(confusion_matrix, annot=True)\n",
    "\n",
    "\n",
    "\n",
    "#Adding labels to confusion matrix\n",
    "confusion_matrix = pd.DataFrame(confusion_matrix, columns=list(y_labels_encoded.values()), index=list(y_labels_encoded.values()))\n",
    "\n",
    "print(\"The rows represents the true values or observations\")\n",
    "print(\"The columns respresent the model's predictions\")\n",
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
